import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report
from xgboost import XGBClassifier
import joblib

"""
Name: Avira
Institution: DBS Bank Ltd. Singapore
Project: Bank Transaction Fraud Detection Classification
"""

# Load the clustered data
df = pd.read_csv('data_clustering.csv')

# 1. Data Preparation
def prepare_data():
    X = df.drop('Target', axis=1)
    y = df['Target']
    
    # Split data
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    return X_train, X_test, y_train, y_test

X_train, X_test, y_train, y_test = prepare_data()

# 2. Model Building and Evaluation
def evaluate_model(y_true, y_pred, model_name):
    print(f"\n{model_name} Performance Metrics:")
    print(f"Accuracy: {accuracy_score(y_true, y_pred):.4f}")
    print(f"Precision: {precision_score(y_true, y_pred, average='weighted'):.4f}")
    print(f"Recall: {recall_score(y_true, y_pred, average='weighted'):.4f}")
    print(f"F1-Score: {f1_score(y_true, y_pred, average='weighted'):.4f}")
    print("\nDetailed Classification Report:")
    print(classification_report(y_true, y_pred))

def build_models():
    # Decision Tree
    dt_model = DecisionTreeClassifier(random_state=42)
    dt_model.fit(X_train, y_train)
    dt_pred = dt_model.predict(X_test)
    evaluate_model(y_test, dt_pred, "Decision Tree")
    joblib.dump(dt_model, "decision_tree_model.h5")
    
    # Random Forest
    rf_model = RandomForestClassifier(random_state=42)
    rf_model.fit(X_train, y_train)
    rf_pred = rf_model.predict(X_test)
    evaluate_model(y_test, rf_pred, "Random Forest")
    
    # Gradient Boosting
    gb_model = GradientBoostingClassifier(random_state=42)
    gb_model.fit(X_train, y_train)
    gb_pred = gb_model.predict(X_test)
    evaluate_model(y_test, gb_pred, "Gradient Boosting")
    
    # XGBoost
    xgb_model = XGBClassifier(random_state=42)
    xgb_model.fit(X_train, y_train)
    xgb_pred = xgb_model.predict(X_test)
    evaluate_model(y_test, xgb_pred, "XGBoost")
    
    # Save best performing model
    models = {
        'Decision Tree': (dt_model, accuracy_score(y_test, dt_pred)),
        'Random Forest': (rf_model, accuracy_score(y_test, rf_pred)),
        'Gradient Boosting': (gb_model, accuracy_score(y_test, gb_pred)),
        'XGBoost': (xgb_model, accuracy_score(y_test, xgb_pred))
    }
    
    best_model_name = max(models.items(), key=lambda x: x[1][1])[0]
    best_model = models[best_model_name][0]
    joblib.dump(best_model, "explore__classification.h5")
    
    return best_model_name, best_model

best_model_name, best_model = build_models()

# 3. Hyperparameter Tuning
def tune_model(best_model_name):
    if best_model_name == "Random Forest":
        param_grid = {
            'n_estimators': [100, 200, 300],
            'max_depth': [10, 20, 30],
            'min_samples_split': [2, 5, 10],
            'min_samples_leaf': [1, 2, 4]
        }
        base_model = RandomForestClassifier(random_state=42)
    
    elif best_model_name == "XGBoost":
        param_grid = {
            'max_depth': [3, 5, 7],
            'learning_rate': [0.01, 0.1, 0.3],
            'n_estimators': [100, 200, 300],
            'subsample': [0.8, 0.9, 1.0]
        }
        base_model = XGBClassifier(random_state=42)
    
    else:  # Decision Tree or Gradient Boosting
        param_grid = {
            'max_depth': [3, 5, 7, 10],
            'min_samples_split': [2, 5, 10],
            'min_samples_leaf': [1, 2, 4]
        }
        base_model = DecisionTreeClassifier(random_state=42) if best_model_name == "Decision Tree" else GradientBoostingClassifier(random_state=42)
    
    # Perform GridSearchCV
    grid_search = GridSearchCV(
        estimator=base_model,
        param_grid=param_grid,
        cv=5,
        scoring='accuracy',
        n_jobs=-1
    )
    
    grid_search.fit(X_train, y_train)
    
    # Evaluate best model
    best_tuned_model = grid_search.best_estimator_
    tuned_pred = best_tuned_model.predict(X_test)
    evaluate_model(y_test, tuned_pred, f"Tuned {best_model_name}")
    
    # Save tuned model
    joblib.dump(best_tuned_model, "tuning_classification.h5")
    
    # Print improvement
    print("\nHyperparameter Tuning Results:")
    print(f"Best Parameters: {grid_search.best_params_}")
    print(f"Best Cross-validation Score: {grid_search.best_score_:.4f}")

tune_model(best_model_name)

# 4. Feature Importance Analysis
def analyze_feature_importance(model, feature_names):
    if hasattr(model, 'feature_importances_'):
        importances = model.feature_importances_
        indices = np.argsort(importances)[::-1]
        
        plt.figure(figsize=(12, 6))
        plt.title('Feature Importances')
        plt.bar(range(X_train.shape[1]), importances[indices])
        plt.xticks(range(X_train.shape[1]), [feature_names[i] for i in indices], rotation=45)
        plt.tight_layout()
        plt.show()

analyze_feature_importance(best_model, X_train.columns)
